{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import getopt\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "#from Bio.SeqUtils import GC\n",
    "import time# import time, gmtime, strftime\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import csv\n",
    "#from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import islice       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iterator(iterator, batch_size):\n",
    "    \"\"\"Returns lists of length batch_size.\n",
    "\n",
    "    This can be used on any iterator, for example to batch up\n",
    "    SeqRecord objects from Bio.SeqIO.parse(...), or to batch\n",
    "    Alignment objects from Bio.AlignIO.parse(...), or simply\n",
    "    lines from a file handle.\n",
    "\n",
    "    This is a generator function, and it returns lists of the\n",
    "    entries from the supplied iterator.  Each list will have\n",
    "    batch_size entries, although the final list may be shorter.\n",
    "    \"\"\"\n",
    "    entry = True  # Make sure we loop once\n",
    "    while entry:\n",
    "        batch = []\n",
    "        while len(batch) < batch_size:\n",
    "            try:\n",
    "                entry = next(iterator)\n",
    "            except StopIteration:\n",
    "                entry = None\n",
    "            if entry is None:\n",
    "                # End of file\n",
    "                break\n",
    "            batch.append(entry)\n",
    "        if batch:\n",
    "            yield batch\n",
    "            \n",
    "def batch_iterator3(iterator, batch_size):\n",
    "    \"\"\"Returns lists of length batch_size.\n",
    "\n",
    "       a modified version of batch_iterator() which replaces original fasta id \n",
    "       with the positional fasta id, and stores in a temporary file\n",
    "       count  starts with 1\n",
    "    \"\"\"\n",
    "    entry = True  # Make sure we loop once\n",
    "    counter=0\n",
    "    while entry:\n",
    "        batch_names=[]\n",
    "        batch = []\n",
    "        while len(batch) < batch_size:\n",
    "            try:\n",
    "                #origianlly was iterator.next()\n",
    "                #changed for py3 compatibility\n",
    "                #needs python 2.6+\n",
    "                entry = next(iterator)\n",
    "            except StopIteration:\n",
    "                entry = None\n",
    "            if entry is None:\n",
    "                # End of file\n",
    "                break\n",
    "            counter+=1\n",
    "            #entry._id=entry.id\n",
    "            entry.id=str(counter)\n",
    "            batch.append(entry)\n",
    "            \n",
    "        if batch:\n",
    "            yield batch\n",
    "            \n",
    "def joinDescriptionColumns(descr_columns):\n",
    "    merged=''\n",
    "    for row in descr_columns.dropna():\n",
    "        if (row != None):\n",
    "            #print(merged)\n",
    "            merged+=row+' '\n",
    "    #print(descr_columns)\n",
    "    return merged.strip()\n",
    "\n",
    "def usage():\n",
    "    print(\"\\nThis is the usage function\\n\")\n",
    "#    print 'Usage: '+sys.argv[0]+' -i <input_file> [-o <output>] [-l <minimum length>]'\n",
    "#    print 'Example: '+sys.argv[0]+' -i input.fasta -o output.fasta -l 100'\n",
    "\n",
    "\n",
    "    \n",
    "def extractFeatures(ids, filename,md):\n",
    "    features=[]\n",
    "    pos=0\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):\n",
    "        pos+=1\n",
    "        if record.name in ids:\n",
    "            features.append({'qid':record.id, 'position':pos, 'descr':record.description, 'seq':str(record.seq)})\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "def extractFeatures2(ids, filename):#putting in a seq object instead of string\n",
    "    features=[]\n",
    "    pos=0\n",
    "    for record in SeqIO.parse(filename,\"fasta\"):\n",
    "        pos+=1\n",
    "        if record.name in ids:\n",
    "            features.append({'qid':record.id, 'position':pos, 'descr':record.description, 'seq':record})\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "def is_operon(x):\n",
    "    return x['diff1'] or x['diff2']\n",
    "\n",
    "def rel_coordinates(x, md):\n",
    "    \n",
    "    \n",
    "    if ((x['diff1'] < md) or (x['diff2']) <md):\n",
    "        return min(x['diff1'],x['diff2'])\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "    #extracting features by positions with no looping through the whole file\n",
    "def extractFeatures4(positions, generator):#putting in a seq object instead of string\n",
    "    #file_iter = SeqIO.parse(open(filename),\"fasta\")#m.rosea\n",
    "    offset=0\n",
    "    features=[]\n",
    "    #entries=list()\n",
    "    for i in range(len(positions)):\n",
    "        position=positions[i]-offset\n",
    "        offset=positions[i]\n",
    "        record=next(islice(generator, position-1,position))#0 start of a generator coupled with 1 start of fasta ids\n",
    "        \n",
    "        features.append({'qid':record.id, 'position':positions[i], 'descr':record.description, 'seq':record})\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "#this function combines adjacent operons(fragments) into one    input_file = '../76969.assembled.faa'\n",
    "\n",
    "def operonCount(lst):\n",
    "    opCnt=0\n",
    "    state=False\n",
    "    for i in xrange(len(lst)):\n",
    "        if lst[i]:\n",
    "            newState=True\n",
    "            if (state==False) and (newState==True):\n",
    "                opCnt+=1\n",
    "            lst[i]=opCnt\n",
    "            state=newState\n",
    "        else:\n",
    "            state=False\n",
    "    return lst\n",
    "\n",
    "#this function splits adjacent operons, based on distance\n",
    "#for the operons of large size it will artificially break it into pieces\n",
    "\n",
    "def operonCount2(lst, pos, md, min_operon_size):\n",
    "    opCnt=0\n",
    "    state=False\n",
    "    position=0\n",
    "    \n",
    "    \n",
    "    for i in range(len(lst)):\n",
    "        if lst[i]:\n",
    "            newState=True\n",
    "            #position=pos[i]\n",
    "            if (state==False) and (newState==True):\n",
    "                position=pos[i]\n",
    "                opCnt+=1\n",
    "            if (pos[i]>position+md+min_operon_size+5):#!!! needs a fix so large operons won't be affected\n",
    "                opCnt+=1\n",
    "    \n",
    "            lst[i]=opCnt\n",
    "            state=newState\n",
    "        else:\n",
    "            state=False\n",
    "    return lst    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def analyzeStructure(name_string, filter_operons={'CAB':0,'ABC':0}):#fix this for the extended version\n",
    "    for key in filter_operons.keys():\n",
    "    \n",
    "        if key in name_string:\n",
    "            filter_operons[key]=1\n",
    "            return (key, 1)\n",
    "        if key[::-1] in name_string:\n",
    "            filter_operons[key]=-1\n",
    "            return (key, -1)\n",
    "    return (None, None)\n",
    "\n",
    "def concatSeparatedValues(row, sep=\" \"):\n",
    "    concatVal=''\n",
    "    for i in range(output['type'].iloc[1].size):\n",
    "        concatVal+=str(row.iloc[i])+sep\n",
    "    concatVal=concatVal[:-len(sep)]#removes last unnesessary separator\n",
    "    return concatVal.rstrip()\n",
    "\n",
    "def operonParser(op_lst, input_file, op_type=False, full_operons=False, remove_terminal_stop_codon=True):\n",
    "    \n",
    "    \n",
    "    output_lst=list()#list of seq elements for fasta exporting\n",
    "    out=pd.DataFrame()\n",
    "    \n",
    "    #initializing output variables\n",
    "    if op_lst == []:\n",
    "        return 1\n",
    "    if full_operons:\n",
    "        out= pd.DataFrame(columns=['operon #','input_file','type',  'rel_distance','size', 'concat_ids','concat_eval', 'concat_descr', 'C', 'A', 'B', 'full_operon'])\n",
    "    out= pd.DataFrame(columns=['operon #','input_file','type','rel_distance','concat_eval','concat_ids','size',  'concat_descr', 'C', 'A', 'B'])\n",
    "    \n",
    "    for operon in op_lst:\n",
    "        \n",
    "        #print(operon)\n",
    "        operon_structure=''.join(operon['type'].tolist())\n",
    "        #print(operon_structure)\n",
    "        op_type,forward=analyzeStructure(operon_structure)\n",
    "        if op_type:\n",
    "            #converting evalue to float\n",
    "            operon[4]=operon[4].astype(float)#for correct sorting\n",
    "            #reverse operon if needed\n",
    "            #print(operon)\n",
    "            if forward == -1:\n",
    "                #''.join(operons[1].reset_index(drop=True)['type'].sort_index(ascending=False).tolist())\n",
    "                operon=operon.reset_index(drop=True).sort_index(ascending=False)#rookie way   \n",
    "            else:\n",
    "                operon=operon.reset_index(drop=True) #else clause is a bit unnecessary\n",
    "            #print(type(operon))\n",
    "            cnt=int(operon['operon_count'].mean())#!!! needs an assert for integer value\n",
    "            inp_file=input_file\n",
    "            \n",
    "            #ot=operon_structure #inclues extended understanding of an operon\n",
    "            ot=op_type\n",
    "            \n",
    "            \n",
    "            rd=''.join(operon.loc[:, 'rel_coordinates'].astype(str).tolist())\n",
    "            sz=len(operon.index)\n",
    "            \n",
    "            \n",
    "            idx_a=operon[operon.loc[:,'type']=='A'].sort_values(4, ascending=True).head(1).index[0]\n",
    "            idx_b=operon[operon.loc[:,'type']=='B'].sort_values(4, ascending=True).head(1).index[0]\n",
    "            idx_c=operon[operon.loc[:,'type']=='C'].sort_values(4, ascending=True).head(1).index[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            concat_eval= \";\".join([str(x) for x in operon.loc[[idx_c, idx_a, idx_b]][4].astype(str)])\n",
    "            #peron\n",
    "            \n",
    "            \n",
    "            concat_ids=\";\".join([x.id for x in operon.loc[[idx_c, idx_a, idx_b]]['seq']])\n",
    "            concat_descr=\";\".join([x.description for x in operon.loc[[idx_c, idx_a, idx_b]]['seq']])\n",
    "            #str(operons[1][operons[1]['type']=='C']['seq'].values[0].seq)\n",
    "            #takes one value from operon with the smallest e-vaue if multiple values are present\n",
    "            #str(record.seq)\n",
    "#             c_seq=str(operon[operon.loc[:,'type']=='C'].sort_values(4, ascending=True).head(1)['seq'].values[0].seq)\n",
    "#             a_seq=str(operon[operon.loc[:,'type']=='A'].sort_values(4, ascending=True).head(1)['seq'].values[0].seq)\n",
    "#             b_seq=str(operon[operon.loc[:,'type']=='B'].sort_values(4, ascending=True).head(1)['seq'].values[0].seq)\n",
    "\n",
    "\n",
    "            #removing terminal stop codon symbol for concatenation\n",
    "            c_seq=str(operon.loc[idx_c]['seq'].seq)\n",
    "            a_seq=str(operon.loc[idx_a]['seq'].seq)\n",
    "            b_seq=str(operon.loc[idx_b]['seq'].seq)\n",
    "            \n",
    "            if remove_terminal_stop_codon:\n",
    "                if c_seq[-1] == \"*\":\n",
    "                    c_seq=c_seq[:-1]\n",
    "                if a_seq[-1] == \"*\":\n",
    "                    a_seq=a_seq[:-1]\n",
    "                if b_seq[-1] == \"*\":\n",
    "                    b_seq=b_seq[:-1]\n",
    "        \n",
    "            record=SeqRecord(Seq(c_seq+a_seq+b_seq, IUPAC.protein), id=concat_ids, description=concat_descr)\n",
    "#           records.append(record)\n",
    "            \n",
    "            output_lst.append(record)\n",
    "#             if full_operons:\n",
    "#                 full_op=\n",
    "            \n",
    "            \n",
    "            out=out.append(pd.Series({'operon #':cnt, \n",
    "                                  'input_file':inp_file, \n",
    "                                  'type':ot, \n",
    "                                  'rel_distance':rd, \n",
    "                                  'size': sz,\n",
    "                                  'concat_eval': concat_eval,\n",
    "                                  'concat_ids': concat_ids,\n",
    "                                  'concat_descr': concat_descr,\n",
    "                                  'C':c_seq,\n",
    "                                  'A':a_seq,\n",
    "                                  'B':b_seq}), ignore_index=True)\n",
    "                                  \n",
    "          \n",
    "            \n",
    "    return out, output_lst     \n",
    "\n",
    "# all in one function, identifies and counts\n",
    "# all in one function, identifies and counts\n",
    "def operonCount5(inp, position=1):#recursive operon count\n",
    "    '''\n",
    "    takes a series, np.array or list of sorted positions as an input and returns \n",
    "    a numpy array of integers, where 0 indicates  no operon, and a positive value indicates operon number\n",
    "    \n",
    "    '''\n",
    "    beginning=True\n",
    "    inp_size=len(inp)\n",
    "    out=np.empty([inp_size])\n",
    "    out[0]=0 # taking care of the initial value\n",
    "    op_cnt=0\n",
    "    operon=0\n",
    "    while position < (inp_size): # i < 203## we have 1 - 202, and checking for previous position\n",
    "        \n",
    "\n",
    "        if (inp[position] - inp[position-1]) <= min_operon_size:\n",
    "            \n",
    "            if (operon==0): #if starting a new operon appending a previous position\n",
    "                op_cnt+=1\n",
    "                out[position-1]=op_cnt #capturing initial position, and re-writing previous False\n",
    "            operon=op_cnt\n",
    "        else:\n",
    "            operon=0\n",
    "        out[position]=operon\n",
    "        position+=1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body of the main function: Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:69: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    }
   ],
   "source": [
    "model='models/amoCAB'\n",
    "max_distance=3\n",
    "min_operon_size=2# parameter needs more thorough work\n",
    "chunk_size=30000\n",
    "#operon_type=['cab','abc']# use \"!\" symbol to exclude operons\n",
    "operon_type=['all']# use \"!\" symbol to exclude operons\n",
    "output_name=''\n",
    "e_val = 1e-3\n",
    "\n",
    "#initialize to work as a prototype\n",
    "input_file='bugs/43209.assembled.faa'\n",
    "#global model, max_distance, min_operon_size\n",
    "# try:                                \n",
    "#     opts, args = getopt.getopt(argv, \"i:o:e:s:t:m:h\", [\"input=\",\"output=\",\"e_value=\",\"size=\",\"type=\",\"model=\",\"fragment_size=\", \"help\"])\n",
    "# except getopt.GetoptError:          \n",
    "#     usage()                         \n",
    "#     sys.exit(2)                     \n",
    "# for opt, arg in opts:                \n",
    "#     if opt in (\"-h\", \"--help\"):      \n",
    "#         usage()              \n",
    "#         sys.exit() \n",
    "# #        elif opt in (\"--recover_after_failure\"):\n",
    "# #            recover_after_failure = True\n",
    "# #            print \"Recover after failure:\", recover_after_failure\n",
    "#     elif opt in (\"-o\", \"--output\"):\n",
    "#         if arg:\n",
    "#             output_name=arg.strip()\n",
    "#     elif opt in (\"-e\", \"--e_value\"):\n",
    "#         try:\n",
    "#             e_val = float(arg)\n",
    "#         except:\n",
    "#             print \"\\nERROR: Please enter numerical value as -e parameter (default: 1e-3)\"\n",
    "#             usage()\n",
    "#             sys.exit(1)\n",
    "#     elif opt in (\"-s\", \"--size\"):\n",
    "#         if arg:\n",
    "#             try:\n",
    "#                 min_operon_size=int(arg.strip())\n",
    "#             except:\n",
    "#                 print(\"ERROR: Please pass integer value to operon [--size] parameter\")\n",
    "#                 sys.exit(1)\n",
    "\n",
    "#     elif opt in ('-t', '--type'):\n",
    "#         if arg:\n",
    "#             operon_type=arg.strip().split(',')\n",
    "#             #print('Operon type:',operon_type) #debugging message\n",
    "\n",
    "#     elif opt in (\"--fragment_size\"):\n",
    "#         if arg:\n",
    "#             try:\n",
    "#                 chunk_size=abs(int(arg.strip()))\n",
    "#             except:\n",
    "#                 print(\"ERROR: Please pass integer value to operon [--fragmen_size] parameter\")\n",
    "#                 sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     elif opt in (\"-i\", \"--input\"):\n",
    "#         if arg:\n",
    "#             input_file=arg.strip()\n",
    "#             #infiles = arg\n",
    "\n",
    "\n",
    "#            \n",
    "#    \n",
    "try:\n",
    "    #\n",
    "    with open(input_file, \"rU\") as hand_ref:\n",
    "        pass\n",
    "except:\n",
    "    print(\"\\nERROR: Input File [\"+input_file+\"] doesn't exist\")\n",
    "    usage()\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "files=list()\n",
    "sizes={}\n",
    "\n",
    "try:\n",
    "    record_iter = SeqIO.parse(open(input_file),\"fasta\")\n",
    "except:\n",
    "    print(\"\\nERROR: Could not parse Input File [\"+input_file+\"]\")\n",
    "\n",
    "basename=os.path.basename(input_file)\n",
    "\n",
    "\n",
    "\n",
    "#    for i, batch in enumerate(batch_iterator(record_iter, 30000)): #keeps original ids\n",
    "for i, batch in enumerate(batch_iterator3(record_iter, chunk_size)): #uses positional ids\n",
    "\n",
    "    label = i\n",
    "    #f = tempfile.NamedTemporaryFile(delete=False)#exists on closing\n",
    "    f = tempfile.NamedTemporaryFile(mode='w+t')#deleted after f.close()\n",
    "    files.append((label,f))\n",
    "    #f.seek(0)\n",
    "    count = SeqIO.write(batch, f, \"fasta\")\n",
    "    f.flush() #this solves the EOF problem\n",
    "#     with open(filename, \"w\") as handle:\n",
    "#         count = SeqIO.write(batch, handle, \"fasta\")\n",
    "    #print(\"Wrote %i records to %s\" % (count, f.name))\n",
    "    sizes[f.name]=count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#creating dictionary containing labels # may be entirely useles/redundant\n",
    "files2={j.name:i for i,j in files}\n",
    "\n",
    "\n",
    "#main heavylifting part\n",
    "\n",
    "#hmmscan --tblout amocab_hmmscan_mros.tab  amoCAB 2517287028.genes.faa > /dev/null\n",
    "#os.system(\"makeblastdb -in \"+input_ref_0+\" -dbtype nucl -title \"+title_db+\" -out \"+outfile_db+\" -parse_seqids\")\n",
    "fnames=\"\"\n",
    "flabels=\"\"\n",
    "for (l,f) in files:\n",
    "    fnames+=f.name+\" \"\n",
    "    flabels+=str(l)+\" \"\n",
    "#print flabels\n",
    "    #print(l)\n",
    "    #print(f.name)\n",
    "    #parallel -j $1 blastall \"-p blastn -d nt/nt -i \"{}\" -o \"{.}\".xml -e 1e-10 -m 7 -K 100 -b 200\" ::: *.fa\n",
    "    #print('Exists after close:', os.path.exists(f.name))\n",
    "#this prints nicely to stdout, and is caught by p.stdout.read()\n",
    "#cmd=\"parallel -j 8 hmmscan \"+\"-o /dev/null --noali --cpu 1\"+\" --tblout >(tee /dev/stdout)  \" + \"../amoCAB {} ::: \"+fnames\n",
    "#this prints to the file and stdout\n",
    "#0.tab should be deleted if exists\n",
    "if os.path.exists(\"0.tab\"):\n",
    "    os.remove(\"0.tab\")\n",
    "cmd=\"parallel -j 8 hmmscan \"+\"-o /dev/null --noali --cpu 1 -E \"+str(e_val)+\" --tblout >(tee -a 0.tab)  \" + model+\" {} ::: \"+fnames\n",
    "args = shlex.split(cmd)\n",
    "#os.system(cmd)\n",
    "p=subprocess.Popen(args,stdout=subprocess.PIPE)\n",
    "#print(p.stdout.read())\n",
    "output=p.stdout.read()\n",
    "#os.system(cmd)\n",
    "#command=\"parallel -j 8 hmmscan \"+\"--cpu 1\"+\" --tblout {}.tab \" + \"../amoCAB {} ::: \"+fnames\n",
    "#print(cmd)\n",
    "\n",
    "\n",
    "#splitting output with reges, since hmmscan sometimes truncates spaces\n",
    "\n",
    "\n",
    "chunks=re.split(r\"#\\s+--- full sequence ---- --- best 1 domain ---- --- domain number estimation ----\", output.decode())\n",
    "\n",
    "#sorting here might be useles\n",
    "total=[]\n",
    "df_scramb=pd.DataFrame()\n",
    "test_cnt=0\n",
    "for chunk in chunks:\n",
    "    if chunk != '':\n",
    "        #print((chunk))\n",
    "\n",
    "        data=chunk.split('\\n')[3:-11]\n",
    "#         if test_cnt <2:\n",
    "#             print(data)\n",
    "        test_cnt+=1\n",
    "        #print(data)\n",
    "        if data:\n",
    "            d=pd.DataFrame([x.split() for x in data])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        query=re.findall('# Query file:\\s*(.*)', chunk)[0]\n",
    "        label=files2[query]\n",
    "        #print(query)\n",
    "        #d['query file']=query\n",
    "        #df.insert(loc=idx, column='A', value=new_col)\n",
    "        d.insert(loc=0, column='query file', value=query)\n",
    "        d.insert(loc=1, column='label', value=label)\n",
    "        #d['label']=files2[query]\n",
    "        df_scramb=df_scramb.append(d)\n",
    "        #total+=chunk.split(\"\\n\")[3:-11]\n",
    "\n",
    "#lots of things here are just for compatibility with no-split version, \n",
    "#they need to be replaced!!!\n",
    "#check for an empty dataframe\n",
    "if df_scramb.empty:\n",
    "    #print(\"\\nNo hits found in the Input File [\"+input_file+\"]\")\n",
    "    sys.exit()\n",
    "df_scramb.sort_values(by='query file', inplace=True)#to fix performance warning\n",
    "df_scramb.set_index(['query file', 'label'], inplace=True)\n",
    "\n",
    "#df_scramb[18]\n",
    "\n",
    "df_scramb.iloc[:,18]=df_scramb.iloc[:,18:].apply(joinDescriptionColumns, axis=1)#this part is also redundant\n",
    "df_scramb=df_scramb.iloc[:,:19]\n",
    "\n",
    "#This block of code is redundant since we introduced positional iformation as fasta ids\n",
    "#df_scramb.sort_index(level=1, inplace=True)#sort by label and then reset index\n",
    "#df_scramb.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "#processing positional fasta ids\n",
    "df_scramb[2]=df_scramb[2].astype(int)\n",
    "df_scramb.reset_index(inplace=True)\n",
    "df_scramb.sort_values(by=2, inplace=True)\n",
    "\n",
    "\n",
    "##hmmscan output df is combined with seq. features extracted from input_file\n",
    "#entire SeqIO.seq object is placed into 'seq' column\n",
    "names=df_scramb[2].tolist()\n",
    "file_iter = SeqIO.parse(open(input_file),\"fasta\")\n",
    "df_scramb=df_scramb.merge(extractFeatures4(names, file_iter), left_on=2, how='inner', right_on='position', suffixes=('',''))\n",
    "file_iter.close()\n",
    "df_scramb.sort_values('position', inplace=True)#should be already sorted, unnecessary\n",
    "#df_scramb.head()\n",
    "\n",
    "\n",
    "\n",
    "#df_scramb.sort_values('position')\n",
    "model2type={'AmoC': 'C', 'AMO': 'A', 'Monooxygenase_B': 'B'}\n",
    "\n",
    "\n",
    "\n",
    "l=df_scramb['position'].tolist()\n",
    "\n",
    "#### SECTION\n",
    "# this section is kept solely of the sake of rel_coordinates functionality, and may be removed\n",
    "# operon counting ignores this section\n",
    "df_scramb['diff1']=abs((np.array(l)-np.array([0] + l[:-1])))#shift to left\n",
    "df_scramb['diff2']=abs(np.array(l)-np.array(l[1:]+[0]))#shift to right\n",
    "#df[(df['diff1'] <= 2) | (df['diff2'] <= 2)]\n",
    "df_scramb['is_operon']=df_scramb[['diff1', 'diff2']].apply(lambda x: x < max_distance).apply(is_operon, axis=1)\n",
    "\n",
    "df_scramb['rel_coordinates']=df_scramb[['diff1', 'diff2']].apply(rel_coordinates, args=(max_distance, ), axis=1)# passing a parameter into apply\n",
    "\n",
    "#### END of Section\n",
    "\n",
    "\n",
    "#df_scramb['operon_count']=operonCount(df_scramb['is_operon'].tolist(), df_scramb['position'].tolist())\n",
    "#df_scramb['operon_count']=operonCount2(df_scramb['is_operon'].tolist(), df_scramb['position'].tolist(), max_distance, min_operon_size)\n",
    "\n",
    "# operon identification and counting takes place here, positional sorted hit ids are taken as an input\n",
    "df_scramb[\"operon_count\"]=operonCount5(df_scramb[2])\n",
    "\n",
    "df_scramb['type']=df_scramb[0].apply(lambda x: model2type[x])\n",
    "df_scramb.head()\n",
    "\n",
    "\n",
    "#groupping by combined operon df into operons by count and placing them into a list for processing\n",
    "operons=list()\n",
    "#output=pd.DataFrame()\n",
    "for count,frame in df_scramb.groupby('operon_count', sort=False):\n",
    "    if count > 0:\n",
    "\n",
    "        operons.append(frame.copy())\n",
    "\n",
    "#ops=list(operons)\n",
    "\n",
    "#check if dot is in the filename\n",
    "#if output_name is specified\n",
    "if output_name:\n",
    "    bn_lst=[output_name]\n",
    "#standard output file names if not specified\n",
    "else:\n",
    "    bn_lst=basename.split(\".\")\n",
    "    bn_lst[0]=\"cab_\"+bn_lst[0]\n",
    "#splitting basename into a lists\n",
    "\n",
    "if len(bn_lst)>1:\n",
    "    outfile1='.'.join(bn_lst[:-1])+\".tsv\"\n",
    "    outfile2='.'.join(bn_lst[:-1])+\".fasta\"\n",
    "    outfile3='.'.join(bn_lst[:-1])+\".tab\"\n",
    "else:\n",
    "    outfile1='.'.join(bn_lst)+\".tsv\"\n",
    "    outfile2='.'.join(bn_lst)+\".fasta\"\n",
    "    outfile3='.'.join(bn_lst)+\".tab\"\n",
    "\n",
    "#print(frame)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body of the main function: Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if operons != []:\n",
    "    final_frame, output_list=operonParser(operons, basename)\n",
    "else:\n",
    "    final_frame=None\n",
    "    output_list=None\n",
    "    print(\"\\nNo operons detected in the Input File [\"+input_file+\"]\")\n",
    "    #need to convert this block into a function\n",
    "    if 'all' not in operon_type:\n",
    "        df_scramb['seq']=df_scramb['seq'].apply(lambda x: str(x.seq)) #converting SeqIO object to string\n",
    "        df_scramb['query file']=input_file\n",
    "        try:\n",
    "            df_scramb.to_csv(outfile3[4:], sep='\\t') # remove cab_ from filename\n",
    "\n",
    "        except:\n",
    "            print(\"ERROR: could not create output file [\"+outfile3[4:]+\"]\")\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#    \n",
    "#    if len(bn_lst)>1:\n",
    "#        outfile1='.'.join(bn_lst[:-1])+\".tsv\"\n",
    "#        outfile2='.'.join(bn_lst[:-1])+\".fasta\"\n",
    "#        outfile3='.'.join(bn_lst[:-1])+\".tab\"\n",
    "#    else:\n",
    "#        outfile1='.'.join(bn_lst)+\".tsv\"\n",
    "#        outfile2='.'.join(bn_lst)+\".fasta\"\n",
    "#        outfile3='.'.join(bn_lst)+\".tab\"\n",
    "\n",
    "#outfile1 = \".tsv\"\n",
    "#outfile2 = \"out4.fasta\"\n",
    "\n",
    "#if we got till here we should have some data in operons list\n",
    "#it might be not abc/cab though\n",
    "if ((isinstance(final_frame, pd.DataFrame)) and (not final_frame.empty)):\n",
    "    try:\n",
    "        final_frame.to_csv(outfile1, sep='\\t', header=True)\n",
    "    except:\n",
    "        print(\"ERROR: could not create output file [\"+outfile1+\"]\")\n",
    "elif operons !=[]: #create empty file to indicate some operons but not the ones of /cab,abc/\n",
    "    with open(outfile1, 'w'):\n",
    "        os.utime(outfile1, None)\n",
    "\n",
    "#if len(ids)==len(sequences):\n",
    "records=list()\n",
    "\n",
    "if ((isinstance(output_list,list)) and (output_list !=[])):    \n",
    "    try:\n",
    "        with open(outfile2, \"w\") as output_handle:\n",
    "            SeqIO.write(output_list, output_handle, \"fasta\")\n",
    "    except:\n",
    "        print(\"ERROR: could not create output file [\"+outfile2+\"]\")\n",
    "\n",
    "elif operons!=[]: #referring back to the groubpy statement: if there are operons, create empty file\n",
    "    with open(outfile2, 'w'):\n",
    "        os.utime(outfile2, None)        \n",
    "\n",
    "if 'all' in operon_type:\n",
    "    df_scramb['seq']=df_scramb['seq'].apply(lambda x: str(x.seq)) #converting SeqIO object to string\n",
    "    df_scramb['query file']=input_file\n",
    "    try:\n",
    "        df_scramb.to_csv(outfile3, sep='\\t')\n",
    "    except:\n",
    "        print(\"ERROR: could not create output file [\"+outfile3+\"]\")\n",
    "\n",
    "\n",
    "\n",
    "####closing temporary files#####            \n",
    "for (l,f) in files:\n",
    "    #print(l)\n",
    "    #print(f.name)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operons=[]\n",
    "operons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for count,frame in df_scramb.groupby('operon_count', sort=False):\n",
    "    if count > 0:\n",
    "\n",
    "        operons.append(frame.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query file</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>descr</th>\n",
       "      <th>position</th>\n",
       "      <th>qid</th>\n",
       "      <th>seq</th>\n",
       "      <th>diff1</th>\n",
       "      <th>diff2</th>\n",
       "      <th>is_operon</th>\n",
       "      <th>rel_coordinates</th>\n",
       "      <th>operon_count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tmp/tmpncpib233</td>\n",
       "      <td>0</td>\n",
       "      <td>Monooxygenase_B</td>\n",
       "      <td>PF04744.11</td>\n",
       "      <td>9824</td>\n",
       "      <td>-</td>\n",
       "      <td>9.9e-125</td>\n",
       "      <td>403.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1e-124</td>\n",
       "      <td>...</td>\n",
       "      <td>draft_100040163</td>\n",
       "      <td>9824</td>\n",
       "      <td>draft_100040163</td>\n",
       "      <td>(V, G, A, K, K, Q, T, V, M, A, A, K, K, I, R, ...</td>\n",
       "      <td>2189</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tmp/tmpncpib233</td>\n",
       "      <td>0</td>\n",
       "      <td>AMO</td>\n",
       "      <td>PF02461.15</td>\n",
       "      <td>9825</td>\n",
       "      <td>-</td>\n",
       "      <td>6.1e-82</td>\n",
       "      <td>262.6</td>\n",
       "      <td>17.4</td>\n",
       "      <td>8e-82</td>\n",
       "      <td>...</td>\n",
       "      <td>draft_100040164</td>\n",
       "      <td>9825</td>\n",
       "      <td>draft_100040164</td>\n",
       "      <td>(M, N, E, V, Q, S, E, E, L, R, A, K, E, V, K, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/tmp/tmpncpib233</td>\n",
       "      <td>0</td>\n",
       "      <td>AmoC</td>\n",
       "      <td>PF04896.11</td>\n",
       "      <td>9826</td>\n",
       "      <td>-</td>\n",
       "      <td>1.5e-69</td>\n",
       "      <td>221.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.8e-69</td>\n",
       "      <td>...</td>\n",
       "      <td>draft_100040165</td>\n",
       "      <td>9826</td>\n",
       "      <td>draft_100040165</td>\n",
       "      <td>(M, A, Q, T, H, A, T, N, D, L, A, V, G, S, G, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2190</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         query file  label                0           1     2  3         4  \\\n",
       "3  /tmp/tmpncpib233      0  Monooxygenase_B  PF04744.11  9824  -  9.9e-125   \n",
       "4  /tmp/tmpncpib233      0              AMO  PF02461.15  9825  -   6.1e-82   \n",
       "5  /tmp/tmpncpib233      0             AmoC  PF04896.11  9826  -   1.5e-69   \n",
       "\n",
       "       5     6         7 ...             descr position              qid  \\\n",
       "3  403.9   0.1  1.1e-124 ...   draft_100040163     9824  draft_100040163   \n",
       "4  262.6  17.4     8e-82 ...   draft_100040164     9825  draft_100040164   \n",
       "5  221.7  18.6   1.8e-69 ...   draft_100040165     9826  draft_100040165   \n",
       "\n",
       "                                                 seq diff1 diff2 is_operon  \\\n",
       "3  (V, G, A, K, K, Q, T, V, M, A, A, K, K, I, R, ...  2189     1      True   \n",
       "4  (M, N, E, V, Q, S, E, E, L, R, A, K, E, V, K, ...     1     1      True   \n",
       "5  (M, A, Q, T, H, A, T, N, D, L, A, V, G, S, G, ...     1  2190      True   \n",
       "\n",
       "  rel_coordinates operon_count type  \n",
       "3               1          1.0    B  \n",
       "4               1          1.0    A  \n",
       "5               1          1.0    C  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def operonParser(op_lst, input_file, op_type=False, full_operons=False, remove_terminal_stop_codon=True):\n",
    "    \n",
    "    \n",
    "    output_lst=list()#list of seq elements for fasta exporting\n",
    "    out=pd.DataFrame()\n",
    "    \n",
    "    #initializing output variables\n",
    "    if op_lst == []:\n",
    "        return 1\n",
    "    if full_operons:\n",
    "        out= pd.DataFrame(columns=['operon #','input_file','type',  'rel_distance','size', 'concat_ids','concat_eval', 'concat_descr', 'C', 'A', 'B', 'full_operon'])\n",
    "    out= pd.DataFrame(columns=['operon #','input_file','type','rel_distance','concat_eval','concat_ids','size',  'concat_descr', 'C', 'A', 'B'])\n",
    "    \n",
    "    for operon in op_lst:\n",
    "        \n",
    "        #make a copy so that no type error occurs\n",
    "        operon=operon.copy()\n",
    "        #print(operon)\n",
    "        operon_structure=''.join(operon['type'].tolist())\n",
    "        #print(operon_structure)\n",
    "        op_type,forward=analyzeStructure(operon_structure)\n",
    "        if op_type:\n",
    "            #converting evalue to float\n",
    "            operon[4]=operon[4].astype(float)#for correct sorting\n",
    "            #reverse operon if needed\n",
    "            #print(operon)\n",
    "            if forward == -1:\n",
    "                #''.join(operons[1].reset_index(drop=True)['type'].sort_index(ascending=False).tolist())\n",
    "                operon=operon.reset_index(drop=True).sort_index(ascending=False)#rookie way   \n",
    "            else:\n",
    "                operon=operon.reset_index(drop=True) #else clause is a bit unnecessary\n",
    "            #print(type(operon))\n",
    "            cnt=int(operon['operon_count'].mean())#!!! needs an assert for integer value\n",
    "            inp_file=input_file\n",
    "            \n",
    "            #ot=operon_structure #inclues extended understanding of an operon\n",
    "            ot=op_type\n",
    "            \n",
    "            \n",
    "            rd=''.join(operon.loc[:, 'rel_coordinates'].astype(str).tolist())\n",
    "            sz=len(operon.index)\n",
    "            \n",
    "            \n",
    "            idx_a=operon[operon.loc[:,'type']=='A'].sort_values(4, ascending=True).head(1).index[0]\n",
    "            idx_b=operon[operon.loc[:,'type']=='B'].sort_values(4, ascending=True).head(1).index[0]\n",
    "            idx_c=operon[operon.loc[:,'type']=='C'].sort_values(4, ascending=True).head(1).index[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            concat_eval= \";\".join([str(x) for x in operon.loc[[idx_c, idx_a, idx_b]][4].astype(str)])\n",
    "            #peron\n",
    "            \n",
    "            \n",
    "            concat_ids=\";\".join([x.id for x in operon.loc[[idx_c, idx_a, idx_b]]['seq']])\n",
    "            concat_descr=\";\".join([x.description for x in operon.loc[[idx_c, idx_a, idx_b]]['seq']])\n",
    "            #str(operons[1][operons[1]['type']=='C']['seq'].values[0].seq)\n",
    "            #takes one value from operon with the smallest e-vaue if multiple values are present\n",
    "            #str(record.seq)\n",
    "#             c_seq=str(operon[operon.loc[:,'type']=='C'].sort_values(4, ascending=True).head(1)['seq'].values[0].seq)\n",
    "#             a_seq=str(operon[operon.loc[:,'type']=='A'].sort_values(4, ascending=True).head(1)['seq'].values[0].seq)\n",
    "#             b_seq=str(operon[operon.loc[:,'type']=='B'].sort_values(4, ascending=True).head(1)['seq'].values[0].seq)\n",
    "\n",
    "\n",
    "            #removing terminal stop codon symbol for concatenation\n",
    "            c_seq=str(operon.loc[idx_c]['seq'].seq)\n",
    "            a_seq=str(operon.loc[idx_a]['seq'].seq)\n",
    "            b_seq=str(operon.loc[idx_b]['seq'].seq)\n",
    "            \n",
    "            if remove_terminal_stop_codon:\n",
    "                if c_seq[-1] == \"*\":\n",
    "                    c_seq=c_seq[:-1]\n",
    "                if a_seq[-1] == \"*\":\n",
    "                    a_seq=a_seq[:-1]\n",
    "                if b_seq[-1] == \"*\":\n",
    "                    b_seq=b_seq[:-1]\n",
    "        \n",
    "            record=SeqRecord(Seq(c_seq+a_seq+b_seq, IUPAC.protein), id=concat_ids, description=concat_descr)\n",
    "#           records.append(record)\n",
    "            \n",
    "            output_lst.append(record)\n",
    "#             if full_operons:\n",
    "#                 full_op=\n",
    "            \n",
    "            \n",
    "            out=out.append(pd.Series({'operon #':cnt, \n",
    "                                  'input_file':inp_file, \n",
    "                                  'type':ot, \n",
    "                                  'rel_distance':rd, \n",
    "                                  'size': sz,\n",
    "                                  'concat_eval': concat_eval,\n",
    "                                  'concat_ids': concat_ids,\n",
    "                                  'concat_descr': concat_descr,\n",
    "                                  'C':c_seq,\n",
    "                                  'A':a_seq,\n",
    "                                  'B':b_seq}), ignore_index=True)\n",
    "                                  \n",
    "          \n",
    "            \n",
    "    return out, output_lst  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "0\n",
      "-1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "t='cabcabc'\n",
    "operon_types={'abc','cba','cab', 'bac'}\n",
    "for op in operon_types:\n",
    "    print(t.find(op, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'operonParser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-e4a7898c1865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperonParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'operonParser' is not defined"
     ]
    }
   ],
   "source": [
    "f, o=operonParser(operons, basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-130-4a7aca440f45>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-130-4a7aca440f45>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def find_subOperon(inp, types, start):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cab', 0)], [('abc', 1)]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=[]\n",
    "for op in operon_types:\n",
    "    pos=t.find(op)\n",
    "    if pos != -1:\n",
    "        output.append([(op, pos)])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t='cabcab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cab', 0)], [('abc', 1)]]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(x, t.find(x))] for x in operon_types if t.find(x) != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(operon_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "output=[[(x, t.find(x))] for x in operon_types if t.find(x) != -1] #initialize list\n",
    "for i in range(len(output)): # looping for the length of the possible operon list\n",
    "        #print(output[i])\n",
    "    min_pos=np.inf\n",
    "    for op in operon_types:\n",
    "        \n",
    "        pos=t.find(op, (output[i][-1][1]+len(output[i][-1][0])))\n",
    "        #min_pos=pos\n",
    "        if (pos !=-1) and (pos < min_pos):\n",
    "            min_pos=pos\n",
    "            min_op=op\n",
    "    if (min_pos !=-1) and (min_pos != np.inf) :\n",
    "        output[i]+=[(min_op, min_pos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cab', 0), ('cab', 3)], [('abc', 1)]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen=0\n",
    "for i in range(len(output)):\n",
    "    ln=len(output[i])\n",
    "    if  ln > maxlen:\n",
    "        maxlen=ln\n",
    "        max_ind=i\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(list(map(len, operon_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiple_operons_lookup(raw_operon_code, operon_types,overlapping=False):\n",
    "    '''\n",
    "    function takes the code names of the composite operon and the accepted operon types\n",
    "    and returns a list with the possible combinations of simple operons found within composite operon.\n",
    "    No overlapping genes is allowed by default.\n",
    "    '''\n",
    "    #how many full operons we can fit into raw_operon_code variable\n",
    "    #depending on how we are looking: overlapping vs non-overlapping\n",
    "    if overlapping: \n",
    "        lookup_depth=int(len(raw_operon_code)-min(list(map(len, operon_types)))+1)\n",
    "    else:\n",
    "        lookup_depth=int(len(raw_operon_code)/min(list(map(len, operon_types)))) #calculating maximum lookup depth\n",
    "    print(lookup_depth)\n",
    "    output=[[(x, t.find(x))] for x in operon_types if t.find(x) != -1] #initialize list\n",
    "    lookup_depth -=1\n",
    "    while lookup_depth > 0: # enter the loop if multiple operons could be found\n",
    "        for i in range(len(output)): # looping for the length of the possible operon list\n",
    "                #print(output[i])\n",
    "            min_pos=np.inf\n",
    "            for op in operon_types: # looping for the possible operon types\n",
    "                if overlapping:\n",
    "                    pos=t.find(op, (output[i][-1][1]+1))\n",
    "                else:\n",
    "                    pos=t.find(op, (output[i][-1][1]+len(output[i][-1][0])))\n",
    "                #min_pos=pos\n",
    "                if (pos !=-1) and (pos < min_pos):\n",
    "                    min_pos=pos\n",
    "                    min_op=op\n",
    "            if (min_pos !=-1) and (min_pos != np.inf) :\n",
    "                output[i]+=[(min_op, min_pos)]\n",
    "        lookup_depth -=1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('cab', 0), ('cab', 3)], [('abc', 1)]]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t='cabcab'\n",
    "operon_types={'abc','cba','cab', 'bac'}\n",
    "\n",
    "outp=multiple_operons_lookup(t, operon_types, overlapping=False)\n",
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc', 'bac', 'cab', 'cba'}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operon_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'sp'), (10, 'pa'), (14, 'sp'), (20, 'pa')]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_all(a_str, sub_lst):\n",
    "    start = 0\n",
    "    while True:\n",
    "        for sub in sub_lst:\n",
    "            start = a_str.find(sub, start)\n",
    "            if start == -1: \n",
    "                return\n",
    "            yield (start, sub)\n",
    "            start += len(sub) # use start += 1 to find overlapping matches\n",
    "\n",
    "list(find_all('tramspam spam spam spam', ['sp', 'pa'])) # [0, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cabcab'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos= t.find('abc',0):\n",
    "if pos != -1:\n",
    "    d['abc']=pos\n",
    "    pos = t.find('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'spam'), (4, 'spam'), (8, 'spam'), (12, 'spam')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(find_all('spamspamspamspam', 'spam')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query file</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>descr</th>\n",
       "      <th>position</th>\n",
       "      <th>qid</th>\n",
       "      <th>seq</th>\n",
       "      <th>diff1</th>\n",
       "      <th>diff2</th>\n",
       "      <th>is_operon</th>\n",
       "      <th>rel_coordinates</th>\n",
       "      <th>operon_count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tmp/tmpncpib233</td>\n",
       "      <td>0</td>\n",
       "      <td>Monooxygenase_B</td>\n",
       "      <td>PF04744.11</td>\n",
       "      <td>9824</td>\n",
       "      <td>-</td>\n",
       "      <td>9.9e-125</td>\n",
       "      <td>403.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1e-124</td>\n",
       "      <td>...</td>\n",
       "      <td>draft_100040163</td>\n",
       "      <td>9824</td>\n",
       "      <td>draft_100040163</td>\n",
       "      <td>(V, G, A, K, K, Q, T, V, M, A, A, K, K, I, R, ...</td>\n",
       "      <td>2189</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tmp/tmpncpib233</td>\n",
       "      <td>0</td>\n",
       "      <td>AMO</td>\n",
       "      <td>PF02461.15</td>\n",
       "      <td>9825</td>\n",
       "      <td>-</td>\n",
       "      <td>6.1e-82</td>\n",
       "      <td>262.6</td>\n",
       "      <td>17.4</td>\n",
       "      <td>8e-82</td>\n",
       "      <td>...</td>\n",
       "      <td>draft_100040164</td>\n",
       "      <td>9825</td>\n",
       "      <td>draft_100040164</td>\n",
       "      <td>(M, N, E, V, Q, S, E, E, L, R, A, K, E, V, K, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/tmp/tmpncpib233</td>\n",
       "      <td>0</td>\n",
       "      <td>AmoC</td>\n",
       "      <td>PF04896.11</td>\n",
       "      <td>9826</td>\n",
       "      <td>-</td>\n",
       "      <td>1.5e-69</td>\n",
       "      <td>221.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.8e-69</td>\n",
       "      <td>...</td>\n",
       "      <td>draft_100040165</td>\n",
       "      <td>9826</td>\n",
       "      <td>draft_100040165</td>\n",
       "      <td>(M, A, Q, T, H, A, T, N, D, L, A, V, G, S, G, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2190</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         query file  label                0           1     2  3         4  \\\n",
       "3  /tmp/tmpncpib233      0  Monooxygenase_B  PF04744.11  9824  -  9.9e-125   \n",
       "4  /tmp/tmpncpib233      0              AMO  PF02461.15  9825  -   6.1e-82   \n",
       "5  /tmp/tmpncpib233      0             AmoC  PF04896.11  9826  -   1.5e-69   \n",
       "\n",
       "       5     6         7 ...             descr position              qid  \\\n",
       "3  403.9   0.1  1.1e-124 ...   draft_100040163     9824  draft_100040163   \n",
       "4  262.6  17.4     8e-82 ...   draft_100040164     9825  draft_100040164   \n",
       "5  221.7  18.6   1.8e-69 ...   draft_100040165     9826  draft_100040165   \n",
       "\n",
       "                                                 seq diff1 diff2 is_operon  \\\n",
       "3  (V, G, A, K, K, Q, T, V, M, A, A, K, K, I, R, ...  2189     1      True   \n",
       "4  (M, N, E, V, Q, S, E, E, L, R, A, K, E, V, K, ...     1     1      True   \n",
       "5  (M, A, Q, T, H, A, T, N, D, L, A, V, G, S, G, ...     1  2190      True   \n",
       "\n",
       "  rel_coordinates operon_count type  \n",
       "3               1          1.0    B  \n",
       "4               1          1.0    A  \n",
       "5               1          1.0    C  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operon #</th>\n",
       "      <th>input_file</th>\n",
       "      <th>type</th>\n",
       "      <th>rel_distance</th>\n",
       "      <th>concat_eval</th>\n",
       "      <th>concat_ids</th>\n",
       "      <th>size</th>\n",
       "      <th>concat_descr</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43209.assembled.faa</td>\n",
       "      <td>CAB</td>\n",
       "      <td>111</td>\n",
       "      <td>1.5e-69;6.1e-82;9.9e-125</td>\n",
       "      <td>draft_100040165;draft_100040164;draft_100040163</td>\n",
       "      <td>3</td>\n",
       "      <td>draft_100040165;draft_100040164;draft_100040163</td>\n",
       "      <td>MAQTHATNDLAVGSGESFGSKTAGHFRRNRIAWGFGALVLAVGAGL...</td>\n",
       "      <td>MNEVQSEELRAKEVKEARAQILDMESLNNPAAMKLYRRLDGILILV...</td>\n",
       "      <td>VGAKKQTVMAAKKIRSRLGLTSIVLSALVLFSGEVLAHGERAQLAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>43209.assembled.faa</td>\n",
       "      <td>CAB</td>\n",
       "      <td>111</td>\n",
       "      <td>1.9e-91;2.1e-86;2.3e-133</td>\n",
       "      <td>draft_100068514;draft_100068513;draft_100068512</td>\n",
       "      <td>3</td>\n",
       "      <td>draft_100068514;draft_100068513;draft_100068512</td>\n",
       "      <td>MSAVMKSTERGGAGLQSARKIFNAWPVALGVAGVAALLLFYRLYQG...</td>\n",
       "      <td>MTANDQAVLDVAEMSPKIAKWSRTMDILVVIVAAFLIMSVSHIGFL...</td>\n",
       "      <td>MILKFRKIILACLAVAALLISVFLPQTAAAHGERATEPSIRTRSVH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>43209.assembled.faa</td>\n",
       "      <td>CAB</td>\n",
       "      <td>111</td>\n",
       "      <td>1.1e-82;1e-82;6.4e-126</td>\n",
       "      <td>draft_100084335;draft_100084336;draft_100084337</td>\n",
       "      <td>3</td>\n",
       "      <td>draft_100084335;draft_100084336;draft_100084337</td>\n",
       "      <td>MKTSSIKDVGAVAAPGVAWGKFFAVLIGLAVIFTVYRVYSEATAFT...</td>\n",
       "      <td>MSADVSSRIDAQVDWVVIPLVVVLLGSIFSFEFALLVGDWDYWIDW...</td>\n",
       "      <td>MKFFTKLFALVQGLLLASTMLCALPAQAHGERAQQPALRMRTVHWF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  operon #           input_file type rel_distance               concat_eval  \\\n",
       "0        1  43209.assembled.faa  CAB          111  1.5e-69;6.1e-82;9.9e-125   \n",
       "1        3  43209.assembled.faa  CAB          111  1.9e-91;2.1e-86;2.3e-133   \n",
       "2        4  43209.assembled.faa  CAB          111    1.1e-82;1e-82;6.4e-126   \n",
       "\n",
       "                                        concat_ids size  \\\n",
       "0  draft_100040165;draft_100040164;draft_100040163    3   \n",
       "1  draft_100068514;draft_100068513;draft_100068512    3   \n",
       "2  draft_100084335;draft_100084336;draft_100084337    3   \n",
       "\n",
       "                                      concat_descr  \\\n",
       "0  draft_100040165;draft_100040164;draft_100040163   \n",
       "1  draft_100068514;draft_100068513;draft_100068512   \n",
       "2  draft_100084335;draft_100084336;draft_100084337   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MAQTHATNDLAVGSGESFGSKTAGHFRRNRIAWGFGALVLAVGAGL...   \n",
       "1  MSAVMKSTERGGAGLQSARKIFNAWPVALGVAGVAALLLFYRLYQG...   \n",
       "2  MKTSSIKDVGAVAAPGVAWGKFFAVLIGLAVIFTVYRVYSEATAFT...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MNEVQSEELRAKEVKEARAQILDMESLNNPAAMKLYRRLDGILILV...   \n",
       "1  MTANDQAVLDVAEMSPKIAKWSRTMDILVVIVAAFLIMSVSHIGFL...   \n",
       "2  MSADVSSRIDAQVDWVVIPLVVVLLGSIFSFEFALLVGDWDYWIDW...   \n",
       "\n",
       "                                                   B  \n",
       "0  VGAKKQTVMAAKKIRSRLGLTSIVLSALVLFSGEVLAHGERAQLAS...  \n",
       "1  MILKFRKIILACLAVAALLISVFLPQTAAAHGERATEPSIRTRSVH...  \n",
       "2  MKFFTKLFALVQGLLLASTMLCALPAQAHGERAQQPALRMRTVHWF...  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          951\n",
       "1          955\n",
       "2         7635\n",
       "3         9824\n",
       "4         9825\n",
       "5         9826\n",
       "6        12016\n",
       "7        18133\n",
       "8        18134\n",
       "9        18340\n",
       "10       18341\n",
       "11       18342\n",
       "12       21829\n",
       "13       21830\n",
       "14       21831\n",
       "15       29736\n",
       "16       37838\n",
       "17       40388\n",
       "18       70966\n",
       "19       72480\n",
       "20      105576\n",
       "21      107807\n",
       "22      132227\n",
       "23      141562\n",
       "24      169812\n",
       "25      192936\n",
       "26      212081\n",
       "27      215069\n",
       "28      222084\n",
       "29      235570\n",
       "        ...   \n",
       "173    1568979\n",
       "174    1579312\n",
       "175    1594480\n",
       "176    1594481\n",
       "177    1597232\n",
       "178    1609945\n",
       "179    1614706\n",
       "180    1620962\n",
       "181    1621038\n",
       "182    1630420\n",
       "183    1631839\n",
       "184    1636700\n",
       "185    1636701\n",
       "186    1648194\n",
       "187    1648195\n",
       "188    1661751\n",
       "189    1661752\n",
       "190    1662629\n",
       "191    1676853\n",
       "192    1704676\n",
       "193    1707516\n",
       "194    1714062\n",
       "195    1721368\n",
       "196    1739494\n",
       "197    1763108\n",
       "198    1775384\n",
       "199    1776543\n",
       "200    1797504\n",
       "201    1804802\n",
       "202    1805932\n",
       "Name: 2, Length: 203, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all in one function, identifies and counts\n",
    "def operonCount5(inp, position=1):#recursive operon count\n",
    "    '''\n",
    "    takes a series, np.array or list of sorted positions as an input and returns \n",
    "    a numpy array of integers, where 0 indicates  no operon, and a positive value indicates operon number\n",
    "    \n",
    "    '''\n",
    "    beginning=True\n",
    "    inp_size=len(inp)\n",
    "    out=np.empty([inp_size])\n",
    "    out[0]=0 # taking care of the initial value\n",
    "    op_cnt=0\n",
    "    operon=0\n",
    "    while position < (inp_size): # i < 203## we have 1 - 202, and checking for previous position\n",
    "        \n",
    "\n",
    "        if (inp[position] - inp[position-1]) <= min_operon_size:\n",
    "            \n",
    "            if (operon==0): #if starting a new operon appending a previous position\n",
    "                op_cnt+=1\n",
    "                out[position-1]=op_cnt #capturing initial position, and re-writing previous False\n",
    "            operon=op_cnt\n",
    "        else:\n",
    "            operon=0\n",
    "        out[position]=operon\n",
    "        position+=1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   1.,   1.,   1.,   0.,   2.,   2.,   3.,   3.,\n",
       "         3.,   4.,   4.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   5.,   5.,   0.,   0.,   0.,   0.,   0.,   6.,\n",
       "         6.,   0.,   0.,   0.,   7.,   7.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   8.,\n",
       "         8.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   9.,\n",
       "         9.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  10.,  10.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  11.,  11.,   0.,  12.,  12.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  13.,  13.,  14.,\n",
       "        14.,   0.,   0.,  15.,  15.,   0.,   0.,  16.,  16.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  17.,  17.,  18.,  18.,   0.,  19.,\n",
       "        19.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  20.,  20.,  21.,\n",
       "        21.,  22.,  22.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operonCount5(df_scramb[2])\n",
    "#operonCount5([124, 125, 226, 337, 7138, 99139])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180    1620962\n",
       "181    1621038\n",
       "182    1630420\n",
       "183    1631839\n",
       "184    1636700\n",
       "185    1636701\n",
       "186    1648194\n",
       "187    1648195\n",
       "188    1661751\n",
       "189    1661752\n",
       "190    1662629\n",
       "191    1676853\n",
       "192    1704676\n",
       "193    1707516\n",
       "194    1714062\n",
       "195    1721368\n",
       "196    1739494\n",
       "197    1763108\n",
       "198    1775384\n",
       "199    1776543\n",
       "200    1797504\n",
       "201    1804802\n",
       "202    1805932\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scramb[2][180:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def operonCount4(is_opr, inp):\n",
    "    '''\n",
    "    takes a boolean aray of values indicting operon elements and counts operons based on the positional information\n",
    "    and\n",
    "    the total hits ordered positions list\n",
    "    '''\n",
    "    #make a copy of an input array\n",
    "    op_cnt=np.copy(is_opr)# basically for False values\n",
    "    rel_positions=np.where(is_opr==True)[0]\n",
    "    print(rel_positions)\n",
    "    op_counter=0# start counting from 1, not 0\n",
    "\n",
    "    for rel_pos in rel_positions:\n",
    "        if rel_pos == 0: #capturing the beginning of the list clause\n",
    "            op_counter +=1\n",
    "            op_cnt[rel_pos]=op_counter\n",
    "       \n",
    "    \n",
    "        if (inp[rel_pos] - inp[rel_pos -1]) <= min_operon_size:\n",
    "            op_cnt[rel_pos]=op_counter\n",
    "        else:\n",
    "            op_counter+=1\n",
    "            op_cnt[rel_pos]=op_counter\n",
    "    return op_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False, False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([False, True, True, False, False, False, True])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False, False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=[10, 16, 17, 25, 37, 45, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False, False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operonCount4(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n"
     ]
    }
   ],
   "source": [
    "operons=list()\n",
    "for i in range(len(df_scramb[2].index)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
